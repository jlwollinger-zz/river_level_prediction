{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNNC/iD78fOhmoPSEHP1KPf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jlwollinger/river_level_prediction/blob/master/lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPbgb7oc71TY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c0eab7e4-4f39-404d-fca1-0767a62aa2d3"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def get_left_and_right_means(mask):\n",
        "    means_left = []\n",
        "    for i in range(0, len(mask), 10):\n",
        "       intersection_points = []\n",
        "       for j in range(len(mask[i])):\n",
        "           if mask[i][j] == True:\n",
        "               intersection_points.append(j)\n",
        "               break\n",
        "       if len(intersection_points) > 0: \n",
        "           means_left.append(sum(intersection_points) / len(intersection_points))\n",
        "       else:\n",
        "           means_left.append(0)\n",
        "    \n",
        "    means_right = []\n",
        "    for i in range(0, len(mask), 10):\n",
        "       intersection_points = []\n",
        "       for j in range(len(mask[i]) - 1, 0, -1):\n",
        "           if mask[i][j] == True:\n",
        "               intersection_points.append(j)\n",
        "               break\n",
        "       if len(intersection_points) > 0: \n",
        "           means_right.append(sum(intersection_points) / len(intersection_points))\n",
        "       else:\n",
        "           means_left.append(0)\n",
        "           \n",
        "    means_left.extend(means_right)\n",
        "    return means_left\n",
        "\n",
        "\n",
        "  \n",
        "X_train = np.array([])\n",
        "y_train = np.array([])\n",
        "\n",
        "annotations = json.load(open('annotations.json'))\n",
        "\n",
        "values = list(annotations.values())\n",
        "annotations = [a for a in values if a['regions']]\n",
        "\n",
        "for value in annotations: \n",
        "    current_file = value\n",
        "    y = float(current_file['filename'].split('_')[0])\n",
        "    regions = current_file['regions']\n",
        "    if regions != None and regions['0']['shape_attributes']['all_points_x'] != None:\n",
        "        \n",
        "        all_x = regions['0']['shape_attributes']['all_points_x']\n",
        "    \n",
        "        all_y = regions['0']['shape_attributes']['all_points_y']\n",
        "    \n",
        "        all_x = np.array(all_x)\n",
        "        all_y = np.array(all_y)\n",
        "    \n",
        "        xy = np.dstack((all_x.ravel(), all_y.ravel()))[0]\n",
        "    \n",
        "    \n",
        "        mask = np.zeros((1080, 1920))\n",
        "        cv.fillPoly(mask, np.int32([xy]), 1)\n",
        "        mask = mask.astype(bool)\n",
        "    \n",
        "        x = get_left_and_right_means(mask)\n",
        "    \n",
        "        X_train = np.append(X_train, x)\n",
        "        y_train = np.append(y_train, y)\n",
        "    \n",
        "    \n",
        "X_train = X_train.reshape((1291, 216, 1))\n",
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "\n",
        "# Initialising the RNN\n",
        "regressor = Sequential()\n",
        "\n",
        "# Adding the first LSTM layer and some Dropout regularisation\n",
        "regressor.add(LSTM(units = 50, return_sequences = True, input_shape=(X_train.shape[1], 1)))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding a second LSTM layer and some Dropout regularisation\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding a third LSTM layer and some Dropout regularisation\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding a fourth LSTM layer and some Dropout regularisation\n",
        "regressor.add(LSTM(units = 50))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding the output layer\n",
        "regressor.add(Dense(units = 1))\n",
        "\n",
        "# Compiling the RNN\n",
        "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "\n",
        "# Fitting the RNN to the Training set\n",
        "regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1291/1291 [==============================] - 20s 16ms/step - loss: 0.0553\n",
            "Epoch 2/100\n",
            "1291/1291 [==============================] - 20s 16ms/step - loss: 0.0191\n",
            "Epoch 3/100\n",
            "1291/1291 [==============================] - 22s 17ms/step - loss: 0.0127\n",
            "Epoch 4/100\n",
            "1291/1291 [==============================] - 22s 17ms/step - loss: 0.0119\n",
            "Epoch 5/100\n",
            "1291/1291 [==============================] - 21s 16ms/step - loss: 0.0111\n",
            "Epoch 6/100\n",
            "1291/1291 [==============================] - 21s 16ms/step - loss: 0.0109\n",
            "Epoch 7/100\n",
            "1291/1291 [==============================] - 21s 16ms/step - loss: 0.0101\n",
            "Epoch 8/100\n",
            "1291/1291 [==============================] - 21s 16ms/step - loss: 0.0111\n",
            "Epoch 9/100\n",
            "1291/1291 [==============================] - 21s 16ms/step - loss: 0.0102\n",
            "Epoch 10/100\n",
            "1291/1291 [==============================] - 21s 16ms/step - loss: 0.0097\n",
            "Epoch 11/100\n",
            "1291/1291 [==============================] - 21s 16ms/step - loss: 0.0094\n",
            "Epoch 12/100\n",
            "1291/1291 [==============================] - 21s 16ms/step - loss: 0.0098\n",
            "Epoch 13/100\n",
            "1291/1291 [==============================] - 21s 16ms/step - loss: 0.0090\n",
            "Epoch 14/100\n",
            "1291/1291 [==============================] - 21s 16ms/step - loss: 0.0098\n",
            "Epoch 15/100\n",
            "1291/1291 [==============================] - 21s 16ms/step - loss: 0.0085\n",
            "Epoch 16/100\n",
            "1291/1291 [==============================] - 21s 16ms/step - loss: 0.0092\n",
            "Epoch 17/100\n",
            "1291/1291 [==============================] - 21s 16ms/step - loss: 0.0084\n",
            "Epoch 18/100\n",
            "1291/1291 [==============================] - 21s 17ms/step - loss: 0.0087\n",
            "Epoch 19/100\n",
            "1291/1291 [==============================] - 21s 17ms/step - loss: 0.0089\n",
            "Epoch 20/100\n",
            "1291/1291 [==============================] - 21s 16ms/step - loss: 0.0086\n",
            "Epoch 21/100\n",
            "1291/1291 [==============================] - 21s 16ms/step - loss: 0.0082\n",
            "Epoch 22/100\n",
            "1291/1291 [==============================] - 21s 16ms/step - loss: 0.0087\n",
            "Epoch 23/100\n",
            "1291/1291 [==============================] - 21s 16ms/step - loss: 0.0086\n",
            "Epoch 24/100\n",
            "1291/1291 [==============================] - 21s 16ms/step - loss: 0.0084\n",
            "Epoch 25/100\n",
            "1291/1291 [==============================] - 21s 16ms/step - loss: 0.0082\n",
            "Epoch 26/100\n",
            "1291/1291 [==============================] - 21s 16ms/step - loss: 0.0087\n",
            "Epoch 27/100\n",
            "1291/1291 [==============================] - 21s 16ms/step - loss: 0.0086\n",
            "Epoch 28/100\n",
            "1291/1291 [==============================] - 21s 16ms/step - loss: 0.0083\n",
            "Epoch 29/100\n",
            "1291/1291 [==============================] - 21s 16ms/step - loss: 0.0080\n",
            "Epoch 30/100\n",
            "1291/1291 [==============================] - 21s 16ms/step - loss: 0.0086\n",
            "Epoch 31/100\n",
            "1291/1291 [==============================] - 21s 16ms/step - loss: 0.0079\n",
            "Epoch 32/100\n",
            "1291/1291 [==============================] - 21s 16ms/step - loss: 0.0078\n",
            "Epoch 33/100\n",
            "1248/1291 [============================>.] - ETA: 0s - loss: 0.0081"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xe8VFul86BF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISmUjBP08SZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X_test = np.array([])\n",
        "y_test = np.array([])\n",
        "\n",
        "annotations = json.load(open(\"annotations_test.json\"))\n",
        "\n",
        "values = list(annotations.values())\n",
        "annotations = [a for a in values if a['regions']]\n",
        "\n",
        "for value in annotations: \n",
        "    current_file = value\n",
        "    y = float(current_file['filename'].split('_')[0])\n",
        "    regions = current_file['regions']\n",
        "    if regions != None and regions['0']['shape_attributes']['all_points_x'] != None:\n",
        "        \n",
        "        all_x = regions['0']['shape_attributes']['all_points_x']\n",
        "    \n",
        "        all_y = regions['0']['shape_attributes']['all_points_y']\n",
        "    \n",
        "        all_x = np.array(all_x)\n",
        "        all_y = np.array(all_y)\n",
        "    \n",
        "        xy = np.dstack((all_x.ravel(), all_y.ravel()))[0]\n",
        "\n",
        "        mask = np.zeros((1080, 1920))\n",
        "        cv.fillPoly(mask, np.int32([xy]), 1)\n",
        "        mask = mask.astype(bool)\n",
        "\n",
        "        x = get_left_and_right_means(mask)\n",
        "    \n",
        "        X_test = np.append(X_test, x)\n",
        "        y_test = np.append(y_test, y)\n",
        "    \n",
        "    \n",
        "X_test = X_test.reshape((144, 216))\n",
        "\n",
        "\n",
        "predicted = regressor.predict(X_test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}